---
title: |
    Follow the User?!
subtitle: Data Donation Studies for Collecting Digital Trace Data
author:
    - name: Frieder Rodewald
      orcid: 0000-0000-0000-0000
      affiliations: University of Mannheim
    - name: Valerie Hase
      orcid: 0000-0000-0000-0000
      affiliations: LMU Munich
date: today
date-format: long
bibliography: references/references.bib
csl: references/apa.csl
execute:
  eval: false
  echo: true
format:
  unima-quarto-revealjs:
    footer: Data Donation Studies - SPP Annual Meeting
    embed-resources: true
    email-obfuscation: none
    code-line-numbers: true
    code-block-height: 670px
    toc: false
    toc-depth: 3
    number-sections: false
    number-depth: 3
    incremental: false
    slide-level: 2
    slide-number: c
    show-slide-number: all
    title-slide-style: default
    center-title-slide: true
    show-notes: false
    scrollable: true
    smaller: false
    overview: true
    menu: true
    chalkboard: false
    multiplex: false
    transition: fade
    transition-speed: fast
    progress: true
    history: false
    navigation-mode: linear
    keyboard: true
    mouse-wheel: true
    hide-inactive-cursor: true
    hide-cursor-time: 500
    loop: false
    help: true
    slide-tone: false
    preview-links: true
    auto-stretch: true
    margin: 0.14
    center: false
    disable-layout: false
    citations-hover: true
    footnotes-hover: true
    reference-location: document
---

## Session 3Ô∏è‚É£: Data Donation Studies (Researcher Perspective)

üëâ Part of the SPP DFG Project [Integrating Data Donations in Survey Infrastructure](https://data-donation-science.de)

##

::: {.v-center}

*What are methodological decisions researchers have to take in data donation studies?* ü§î

:::

## Data donation study - researcher perspective

![Figure. Data donation study - researcher perspective](images/ablauf-4.jpg){fig-alt="process of data donation study" fig-align="left" width="300"}

## Agenda

1. **Research design & tool set-up**

2. **Data cleaning & augmentation**, including

   üì¢ **Task 3**: Classify search terms

3. **Modelling digital traces**

![Image by Hope House Press via Unsplash](images/agenda.jpg){fig-align="left" width="10%"}

## 1) Research design & tool set-up (Frieder)

![Source: Image by Markus Winkler via Unsplash](images/methods.jpg){fig-alt="image of lupe" fig-align="left" width="300"}

## Step I: Research design & tool set-up

![Figure. Data donation study - researcher perspective](images/ablauf-4a.jpg){fig-alt="process of data donation study" fig-align="left" width="300"}

## Step I: Research design & tool set-up

Key decisions:

-   Which theoretical questions do I want to answer?
-   How do I operationalize key variables via my data donation tool?
-   How do I integrate the tool in surveys & recruit participants?

## Step I: Research design & tool set-up

Key decisions:

-   **Which theoretical questions do I want to answer?**
-   How do I operationalize key variables via my data donation tool?
-   How do I integrate the tool in surveys & recruit participants?

## Step I.I Which questions do I want to answer?

This may sound silly but:

-   Novel method, few empirical applications
-   To date: methodological playground
-   *What good is a method that is not used to advance theories/empirical knowledge?*

## Step I: Research design & tool set-up

Key decisions:

-   Which theoretical questions do I want to answer?
-   **How do I operationalize key variables via my data donation tool?**
-   How do I integrate the tool in surveys & recruit participants?

## Step I.II: How do I operationalize key variables?

Choose a tool, e.g., ...

-   Port [@boeschoten_etal2023] (Netherlands, different platforms)
-   Data Donation Module [@pfiffner_data_2022] (Switzerland, different platforms)
-   WhatsR [@kohne_etal2024] (Germany, WhatsApp)

## Step I.II: How do I operationalize key variables?

-   Participants "upload" data
-   Local extraction, anonymization, & aggregation
-   Users can delete data
-   Informed consent, only then: send to researcher server

## Step I.II: How do I operationalize key variables?

-   Participants "upload" data
-   Local **extraction**, anonymization, & aggregation
-   Users can delete data
-   Informed consent, only then: send to researcher server

## Step I.II: How do I operationalize key variables?

### Extractionüîé:

![Figure. Filtering data - File extraction](images/extraction.jpg){fig-alt="Files in data donation packages" fig-align="left" width="200"}

## Step I.II: How do I operationalize key variables?

### Extractionüîé:

![Figure. Filtering data - Python code](images/filtering.jpg){fig-alt="Python code for extracting files" fig-align="left" width="200"}

## Step I.II: How do I operationalize key variables?

### Extractionüîé:

![Figure. Filtering data - Python code](images/filtering-a.jpg){fig-alt="Python code for extracting files" fig-align="left" width="200"}

## Step I.II: How do I operationalize key variables?

-   Participants "upload" data
-   Local extraction, **anonymization**, & aggregation
-   Users can delete data
-   Informed consent, only then: send to researcher server

## Step I.II: How do I operationalize key variables?

### Anonymization üôà:

![Figure. Anonymization - Example of Whitelists](images/anonymization.jpg){fig-alt="Example whitelists for news outlets" fig-align="left" width="200"}

## Step I.II: How do I operationalize key variables?

### Anonymization üôà:

![Figure. Example of anonymized data](images/anonymization-a.jpg){fig-alt="Example of anonymized data" fig-align="left" width="200"}

## Step I.II: How do I operationalize key variables?

-   Participants "upload" data
-   Local extraction, anonymization, & **aggregation**
-   Users can delete data
-   Informed consent, only then: send to researcher server

## Step I.II: How do I operationalize key variables?

### Aggregation üßÆ:

![Figure. Aggregation - Python code](images/filtering-a.jpg){fig-alt="Python code for aggregation" fig-align="left" width="200"}

## Step I.II: How do I operationalize key variables?

-   Participants "upload" data
-   Local extraction, anonymization, & aggregation
-   Users can **delete data**
-   Informed consent, only then: send to researcher server

## Step I.II: How do I operationalize key variables?

### Data deletion by users ‚ùå:

![Figure. Data deletion](images/deletion.jpg){fig-alt="Example of how users can delete their data" fig-align="left" width="200"}

## Step I.II: How do I operationalize key variables?

This is how much "fun" testing DDTs is:

![Figure. Github issues - Testing the tool](images/testing.jpg){fig-alt="Github screenshot of testing" fig-align="left" width="200"}

## Step I.II: How do I operationalize key variables?

Key issues üö® [@hase_etal2024]

-   Missing documentation by platforms (e.g., file structure)
-   Sudden changes in DDPs
-   Differences across languages & devices
-   Insufficient in-tool classification (e.g., LLM integration)

##

::: {.v-center}

**Let's have a look at the technical set-up üíª:**

[https://github.com/eyra/mono](https://github.com/eyra/mono)

[https://github.com/eyra/feldspar](https://github.com/eyra/feldspar)

:::

---

![Figure. Next setup 1](images/next_1.png){fig-alt="Next workflow screenshots" fig-align="left" width="200"}

---

![Figure. Next setup 2](images/next_2.png){fig-alt="Next workflow screenshots" fig-align="left" width="200"}

---

![Figure. Next setup 3](images/next_3.png){fig-alt="Next workflow screenshots" fig-align="left" width="200"}

---

![Figure. Next setup 4](images/next_4.png){fig-alt="Next workflow screenshots" fig-align="left" width="200"}

---

![Figure. Next setup 5](images/next_5.png){fig-alt="Next workflow screenshots" fig-align="left" width="200"}

---

![Figure. Next setup 6](images/next_6.png){fig-alt="Next workflow screenshots" fig-align="left" width="200"}

---

![Figure. Next setup 7](images/next_7.png){fig-alt="Next workflow screenshots" fig-align="left" width="200"}

---

![Figure. Next setup 8](images/next_8.png){fig-alt="Next workflow screenshots" fig-align="left" width="200"}

---

![Figure. Next setup 9](images/next_9.png){fig-alt="Next workflow screenshots" fig-align="left" width="200"}

---

![Figure. Next setup 10](images/next_10.png){fig-alt="Next workflow screenshots" fig-align="left" width="200"}

## Strategy to make the extraction work

1. Take a look at the DDP; download it, best for multiple time periods and for different languages
2. Understand the structure of the JSON or CSV.
3. Get an example file running.
4. Write the code for the extraction script.
5. Test your script, first locally and then in the wild.
6. Adapt your script.

## Example: Extract list of subscriptions

![Figure. subscriptions.csv](images/subscriptions_csv.jpeg.png){fig-alt="Screenshot of subscriptions.csv" fig-align="left" width="200"}

---

```{.python}
...
    "subscriptions": {
        "extraction_function": ef.extract_subscriptions,
        "possible_filenames": ["Abos.csv", "subscriptions.csv"],
        "title": {
            "en": "Which channels are you subscribed to?",
            "de": "Welche Kan√§le haben Sie abonniert?",
            "nl": "Op welke kanalen ben je geabonneerd?",
        },
    },
...
```

---

```{.python code-line-numbers="1-20"}
def extract_youtube_content_from_zip_folder(zip_file_path, possible_filenames):
    """Extract content from YouTube data export zip file using filenames"""

    try:
        with zipfile.ZipFile(zip_file_path, "r") as zip_ref:
            # Get the list of file names in the zip file
            filenames = zip_ref.namelist()
            # Look for matching files
            for possible_filename in possible_filenames:
                for filename in filenames:
                    if possible_filename in filename:
                        try:
                            # Process based on file extension
                            if filename.endswith(".json"):
                                with zip_ref.open(filename) as json_file:
                                    json_content = json.loads(json_file.read())
                                    return json_content
                            elif file_name.endswith(".csv"):
                                with zip_ref.open(file_name) as csv_file:
                                    csv_content = pd.read_csv(csv_file)
```

---

```{.python code-line-numbers="1-15"}
def extract_subscriptions(subscriptions_csv):
    """Extract YouTube channel subscriptions"""

    # Define column name
    if "Kanaltitel" in subscriptions_csv.columns:
        channel_column = "Kanaltitel"
    else:
        channel_column = "Channel Title"

    # Define description
    channel_name = "Subscribed Channel"

    # Create DataFrame with just the channel names
    subscriptions_df = pd.DataFrame({channel_name: subscriptions_csv[channel_column]})
    return subscriptions_df
```

---

![Figure. Processed subscriptions.csv](images/subscriptions_donated.png){fig-alt="Screenshot of the processed subscriptions.csv" fig-align="left" width="200"}

## Step I: Research design & tool set-up

Key decisions:

-   Which theoretical questions do I want to answer?
-   How do I operationalize key variables via my data donation tool?
-   **How do I integrate the tool in surveys & recruit participants?**

## Step I.III: How do I integrate the tool in surveys & recruit participants?

-   Often: survey, then forwarding to an external site
-   Less often: Integration in existing survey infrastructure [@haim_integrating_2023]

## Step I.III: How do I integrate the tool in surveys & recruit participants?

-   Low response rates [e.g., @hase_haim2024a; @keusch_etal2024]

    - Behavioral intentions as "willingness to donate" high (79-52% of survey respondents)
    - Actual behavior as "participation in data donation" low (37-12% of survey respondents)
    - Well known intention-behavior gap [@kmetty_etal2025]

-   Non-response bias

-   Primary used in non-probability panels (e.g. online access panels)

-   Survey design strategies: For now, ü§ë is the only thing that works.

-   üëâ Again, we will talk about this in session 4Ô∏è‚É£.

## Step I: Research design & tool set-up

![Figure. Data donation study - researcher perspective](images/ablauf-4a.jpg){fig-alt="process of data donation study" fig-align="left" width="300"}

## Step II: Data cleaning & augmentation (Valerie)

![Figure. Data donation study - researcher perspective](images/ablauf-4b.jpg){fig-alt="process of data donation study" fig-align="left" width="300"}


## Step II.I: How do I clean and extend data?

This is how your data may look like:

![Figure. Donated data - example](images/cleaning_1.jpg){fig-alt="Example of donated data" fig-align="left" width="300"}

## Step II.I: How do I clean and extend data?

This is how your data may look like:

![Figure. Donated data - example](images/cleaning_2.jpg){fig-alt="process of data donation study" fig-align="left" width="300"}

## Step II.I: How do I clean and extend data?

-   Manual annotation by participants during data donation
-   APIs/scraping to extend collected data
-   Text-as-data methods for classification

##

::: {.v-center}

**üì¢ Task 3: Classify search terms**

*Download the data for Task 4 from the workshop website. This contains YouTube searches collected from a German social media sample. Either discuss this (no-code group) or do this in R/Python (code group).....*

(1) How you would clean the data?

(2) How you would identify health-related searches using NLP methods?

:::

## Step II.II: How do I check for bias?

-   Errors in representation and measurements, e.g.
    -   based on systematic drop-out [@pak_correcting_2022]
    -   based on systematic misclassification of digital traces [@teblunthuis_etal2024]

üëâ You know the drill: We will talk about this in session 4Ô∏è‚É£.

## Step II: Data cleaning & augmentation

![Figure. Data donation study - researcher perspective](images/ablauf-4b.jpg){fig-alt="process of data donation study" fig-align="left" width="300"}

## Step III: Modelling (Valerie)

![Figure. Data donation study - researcher perspective](images/ablauf-4c.jpg){fig-alt="process of data donation study" fig-align="left" width="300"}

## Step III.I: How do I analyze results?

Think carefully about...

-   How to create indices from different metrics (e.g., liking, sharing, or commenting on content)
-   Hierarchical structure (nested in time, metrics, platforms)
-   Skewed data, non-linearity

## Summary: Researcher perspective üìö

-   **Summary**: Key steps include...

    1.  Research design & tool set-up
    2.  Data cleaning & augmentation
    3.  Modelling

-   **Further literature**:

    -   @boeschoten_privacy-preserving_2022

    -   @carriere_etal2024

##

::: {.v-center}

**Questions?** ü§î

:::

## References {.smallest}
